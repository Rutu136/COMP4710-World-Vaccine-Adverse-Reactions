{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_symptoms(symptom):\n",
    "    categories = {\n",
    "        'pain': ['headache', 'pain', 'pain in extremity', 'chest discomfort', 'chest pain', 'abdominal pain upper', 'pain of skin', 'abdominal pain', 'bone pain', 'back pain', 'neck pain', 'musculoskeletal pain', 'arthralgia', 'myalgia', 'joint swelling', 'muscle spasms', 'muscle tightness', 'muscular weakness', 'joint range of motion decreased', 'musculoskeletal stiffness', 'joint stiffness', 'neck stif'],\n",
    "        'fever/chills': ['pyrexia', 'chills', 'body temperature increased', 'feeling hot', 'feeling cold', 'cold sweat', 'night sweats', 'hyperhidrosis', 'fever', 'influenza', 'influenza like illness', 'covid-19', 'febrile neutropenia', 'feeling abnormal', 'feeling hot and cold', 'feeling cold and hot'],\n",
    "        'fatigue/general discomfort': ['fatigue', 'asthenia', 'malaise', 'lethargy', 'condition aggravated', 'discomfort',],\n",
    "        'skin reactions': ['injection site erythema', 'pruritus', 'injection site pruritus', 'rash', 'erythema', 'rash erythematous', 'rash pruritic', 'hyperhidrosis', 'skin warm', 'skin swelling', 'urticaria', 'skin discolouration', 'skin burning sensation', 'skin lesion', 'skin exfoliation', 'skin induration', 'skin tightness', 'skin irritation', 'skin reaction', 'skin ulcer', 'skin hypertrophy', 'skin atrophy', 'skin nodule', 'skin papilloma', 'skin hyperpigmentation', 'skin hypopigmentation', 'skin haemorrhage', 'skin necrosis', 'skin striae', 'skin wrinkling', 'skin fragility', 'skin exfoliation', 'skin depigmentation'],\n",
    "        'digestive issues': ['nausea', 'vomiting', 'diarrhoea', 'abdominal discomfort', 'dysphagia', 'retching', 'abdominal distension', 'abdominal pain', 'abdominal pain upper', 'abdominal pain lower', 'abdominal tenderness', 'abdominal rigidity', 'abdominal pain right', 'abdominal pain left', 'abdominal pain upper', 'abdominal pain lower', 'abdominal tenderness', 'abdominal rigidity', 'abdominal pain right', 'abdominal pain left', 'abdominal pain upper', 'abdominal pain lower', 'abdominal tenderness', 'abdominal rigidity', 'abdominal pain right'],\n",
    "        'respiratory symptoms': ['dyspnoea', 'cough', 'rhinorrhoea', 'nasal congestion', 'respiratory tract congestion', 'wheezing', 'dysphonia', 'respiratory failure', 'respiratory distress', 'respiratory arrest', 'respiratory depression', 'respiratory disorder', 'respiratory rate increased', 'respiratory tract infection', 'respiratory disorder', ],\n",
    "        'neurological symptoms': ['dizziness', 'paraesthesia', 'hypoaesthesia', 'tremor', 'syncope', 'vertigo', 'seizure', 'loss of consciousness', 'confusional state', 'disorientation', 'presyncope'],\n",
    "        'cardiovascular symptoms': ['palpitations', 'heart rate increased', 'hypertension', 'hypotension', 'tachycardia', 'chest discomfort'],\n",
    "        'musculoskeletal symptoms': ['arthralgia', 'myalgia', 'muscle spasms', 'muscular weakness', 'joint swelling', 'musculoskeletal stiffness', 'joint range of motion decreased', 'muscle tightness'],\n",
    "        'psychiatric symptoms': ['anxiety', 'depression', 'nervousness', 'insomnia', 'somnolence', 'hallucination', 'psychosis'],\n",
    "        'visual and auditory symptoms': ['tinnitus', 'vision blurred', 'eye pain', 'eye swelling', 'photophobia', 'hypoacusis', 'hearing impaired', 'visual impairment', 'visual acuity reduced', 'visual disturbance', 'visual field defect', 'visual brightness', 'visual brightness', 'visual disturbance', 'visual field defect', 'visual acuity reduced', 'visual impairment', 'visual disturbance'],\n",
    "        'hematological symptoms': ['lymphadenopathy', 'full blood count', 'pallor', 'haemoglobin decreased', 'haematocrit decreased', 'red blood cell count decreased', 'white blood cell count decreased', 'platelet count decreased', 'blood iron decreased', 'blood iron increased', 'blood lactate dehydrogenase increased', 'blood bilirubin increased', 'blood creatinine increased', 'blood creatine phosphokinase increased', 'blood urea increased', 'blood uric acid increased', 'blood potassium increased', 'blood sodium decreased', 'blood sodium increased', 'blood chloride decreased', 'blood chloride increased', 'blood calcium decreased', 'blood calcium increased', 'blood albumin decreased', 'blood albumin increased', 'blood alkaline phosphatase increased', 'blood amylase increased', 'blood glucose increased', 'blood glucose decreased', 'blood triglycerides increased', 'blood cholesterol increased', 'blood cholesterol decreased', 'blood triglycerides decreased', 'blood triglycerides increased'],\n",
    "        'urinary symptoms': ['urine analysis', 'urinary issues', 'urinary retention', 'urinary tract infection', 'urinary incontinence',],\n",
    "        'swelling-related symptoms': ['swelling', 'swollen tongue', 'swelling face', 'peripheral swelling', 'peripheral coldness', 'peripheral circulatory failure', 'peripheral ischaemia', 'peripheral sensory neuropathy', 'peripheral motor neuropathy', 'peripheral vascular disorder',],\n",
    "        'systemic infections': ['covid-19', 'influenza like illness', 'herpes zoster', 'cellulitis'],\n",
    "        'allergic reactions': ['hypersensitivity', 'anaphylactic reaction', 'angioedema', 'anaphylactic shock', 'anaphylactoid reaction', 'anaphylactic transfusion reaction', 'anaphylactic response', 'anaphylactic symptom', 'anaphylactic reaction', 'anaphylactic shock', 'anaphylactoid reaction', ],\n",
    "    }\n",
    "    \n",
    "    for category, symptoms in categories.items():\n",
    "        if symptom.lower() in [s.lower() for s in symptoms]:\n",
    "            return category\n",
    "    \n",
    "    return 'Other' \n",
    "\n",
    "# Function to categorize symptoms in a list and return groups\n",
    "def categorize_symptom_list(symptom_list):\n",
    "    categories = [categorize_symptoms(symptom) for symptom in symptom_list.split(', ')]\n",
    "    return ', '.join(set(categories))  # Combine unique categories into a comma-separated string\n",
    "\n",
    "moderna_df['Symptoms_category'] = moderna_df['Symptoms'].apply(categorize_symptom_list)\n",
    "\n",
    "# Function to process the values in Symptoms_category column\n",
    "def process_category(symptoms):\n",
    "    symptoms_list = symptoms.split(', ')\n",
    "    if 'Other' in symptoms_list and len(symptoms_list) > 1:\n",
    "        symptoms_list.remove('Other')\n",
    "        return ', '.join(symptoms_list)\n",
    "    return symptoms\n",
    "\n",
    "# Apply the function to the Symptoms_category column\n",
    "moderna_df['Symptoms_category'] = moderna_df['Symptoms_category'].apply(process_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def extract_moderna_rules(apriori_result):\n",
    "    rules = []\n",
    "    for relation_record in apriori_result:\n",
    "        for ordered_statistic in relation_record.ordered_statistics:\n",
    "            antecedent = list(ordered_statistic.items_base)\n",
    "            consequent = list(ordered_statistic.items_add)\n",
    "            \n",
    "            # Check if 'Moderna vaccine' is in antecedent or consequent\n",
    "            if 'Moderna vaccine' in consequent and len(consequent) == 1:\n",
    "                if antecedent and consequent:\n",
    "                    antecedent_str = ', '.join(antecedent)\n",
    "                    consequent_str = ', '.join(consequent)\n",
    "                    support = relation_record.support\n",
    "                    lift = ordered_statistic.lift\n",
    "                    rule = f\"{antecedent_str} -> {consequent_str} (Support: {support}, Lift: {lift})\"\n",
    "                    rules.append(rule)\n",
    "    return rules\n",
    "\n",
    "association_rules = extract_moderna_rules(results)\n",
    "\n",
    "for rule in association_rules:\n",
    "    print(rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def extract_moderna_rules_with_metrics(apriori_result):\n",
    "    rules = []\n",
    "    supports = []\n",
    "    lifts = []\n",
    "    for relation_record in apriori_result:\n",
    "        for ordered_statistic in relation_record.ordered_statistics:\n",
    "            antecedent = list(ordered_statistic.items_base)\n",
    "            consequent = list(ordered_statistic.items_add)\n",
    "            \n",
    "            # Check if 'Moderna vaccine' is in antecedent or consequent\n",
    "            if 'Moderna vaccine' in consequent and len(consequent) == 1:\n",
    "                if antecedent and consequent:  # Exclude if either antecedent or consequent is empty\n",
    "                    support = relation_record.support\n",
    "                    lift = ordered_statistic.lift\n",
    "                    \n",
    "                    antecedent_str = ', '.join(antecedent)\n",
    "                    consequent_str = ', '.join(consequent)\n",
    "                    \n",
    "                    rules.append(f\"{antecedent_str} -> {consequent_str}\")\n",
    "                    supports.append(support)\n",
    "                    lifts.append(lift)\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    data = pd.DataFrame({'Rules': rules, 'Support': supports, 'Lift': lifts})\n",
    "    return data\n",
    "\n",
    "\n",
    "rules_data = extract_moderna_rules_with_metrics(results)\n",
    "\n",
    "heatmap_data = rules_data.pivot_table(index='Rules', columns='Support', values='Support')\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Association Rules Heatmap')\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Association Rules')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Title: Analyzing COVID-19 Vaccine Adverse Reactions: A Comprehensive Stud\n",
    "## Team Members: Rutu Barvaliya, Dharmit Anghan, Breanna Brown, Raghav Mangat\n",
    "## Group: 8\n",
    "## Course: Comp4710\n",
    "## Section: A01\n",
    "## Professor: Carson\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "vers_data = pd.read_csv(\"2020VAERSDATA.csv\", encoding='latin-1')\n",
    "vers_vax = pd.read_csv(\"2020VAERSVAX.csv\", encoding='latin-1')\n",
    "vers_symptoms = pd.read_csv(\"2020PREPROCESSED_SYMPTOMS.csv\", encoding='latin-1')\n",
    "# Print the total count of VAERS_ID\n",
    "total_count = len(vers_data['VAERS_ID'])\n",
    "print(\"Total count of VAERS_ID:\", total_count)\n",
    "\n",
    "# Remove duplicate VAERS_ID\n",
    "vers_data.drop_duplicates(subset='VAERS_ID', inplace=True)\n",
    "\n",
    "# Print the count after removing duplicates\n",
    "count_after_duplicates = len(vers_data['VAERS_ID'])\n",
    "print(\"Count after removing duplicates:\", count_after_duplicates)\n",
    "\n",
    "\n",
    "\n",
    "# Print the total count of VAERS_ID\n",
    "total_count = len(vers_vax['VAERS_ID'])\n",
    "print(\"Total count of VAERS_ID:\", total_count)\n",
    "\n",
    "# Remove duplicate VAERS_ID\n",
    "vers_vax.drop_duplicates(subset='VAERS_ID', inplace=True)\n",
    "\n",
    "# Print the count after removing duplicates\n",
    "count_after_duplicates = len(vers_vax['VAERS_ID'])\n",
    "print(\"Count after removing duplicates:\", count_after_duplicates)\n",
    "\n",
    "\n",
    "\n",
    "# Print the total count of VAERS_ID\n",
    "total_count = len(vers_symptoms['VAERS_ID'])\n",
    "print(\"Total count of VAERS_ID:\", total_count)\n",
    "\n",
    "# Remove duplicate VAERS_ID\n",
    "vers_symptoms.drop_duplicates(subset='VAERS_ID', inplace=True)\n",
    "\n",
    "# Print the count after removing duplicates\n",
    "count_after_duplicates = len(vers_symptoms['VAERS_ID'])\n",
    "print(\"Count after removing duplicates:\", count_after_duplicates)\n",
    "### Cleaning up 2022VAERSDATA file.\n",
    "# Define a dictionary with columns and their respective predefined values for filling nulls\n",
    "fill_values = {\n",
    "    'OTHER_MEDS': 'No medication',\n",
    "    'CUR_ILL': 'Not applicable',\n",
    "    'HISTORY': 'No concerns',\n",
    "    'PRIOR_VAX': 'Not applicable', \n",
    "    'DIED': 'N',\n",
    "    'DATEDIED': 'Not applicable', \n",
    "    'L_THREAT': 'N', \n",
    "    'ER_VISIT': 'N', \n",
    "    'HOSPITAL':'N',\n",
    "    'HOSPDAYS': 0,\n",
    "    'X_STAY': 'N',\n",
    "    'DISABLE': 'N',\n",
    "    'BIRTH_DEFECT': 'N',\n",
    "    'OFC_VISIT': 'N',\n",
    "    'ER_ED_VISIT': 'N',\n",
    "    'ALLERGIES': 'N'\n",
    "}\n",
    "\n",
    "# Fill null values with predefined values for respective columns\n",
    "for column, value in fill_values.items():\n",
    "    vers_data[column].fillna(value, inplace=True)\n",
    "\n",
    "# Calculate the percentage of null values in each column\n",
    "null_percentages = (vers_data.isnull().sum() / len(vers_data)) * 100\n",
    "print(null_percentages)\n",
    "\n",
    "# List to store columns with more than 50% null values\n",
    "columns_to_drop = []\n",
    "\n",
    "# Iterate through each column's null percentage\n",
    "for column, percentage in null_percentages.items():\n",
    "    if percentage > 50:\n",
    "        columns_to_drop.append(column)\n",
    "\n",
    "# Drop columns with more than 50% null values\n",
    "if columns_to_drop:\n",
    "    vers_data.drop(columns=columns_to_drop, inplace=True)\n",
    "    print(f\"Dropped columns: {columns_to_drop}\")\n",
    "else:\n",
    "    print(\"No columns have more than 50% null values.\")\n",
    "\n",
    "### Cleaning up 2022VAERSVAX file.\n",
    "# Calculate the percentage of null values in each column\n",
    "null_percentages = (vers_vax.isnull().sum() / len(vers_vax)) * 100\n",
    "print(null_percentages)\n",
    "\n",
    "# List to store columns with more than 50% null values\n",
    "columns_to_drop = []\n",
    "\n",
    "# Iterate through each column's null percentage\n",
    "for column, percentage in null_percentages.items():\n",
    "    if percentage > 50:\n",
    "        columns_to_drop.append(column)\n",
    "\n",
    "# Drop columns with more than 50% null values\n",
    "if columns_to_drop:\n",
    "    vers_vax.drop(columns=columns_to_drop, inplace=True)\n",
    "    print(f\"Dropped columns: {columns_to_drop}\")\n",
    "else:\n",
    "    print(\"No columns have more than 50% null values.\")\n",
    "### Cleaning up 2022VAERSSYMPTOMS file.\n",
    "# Define a dictionary with columns and their respective predefined values for filling nulls\n",
    "fill_values = {\n",
    "    'SYMPTOM2': 'No symptom',\n",
    "    'SYMPTOMVERSION2': 0,\n",
    "    'SYMPTOM3': 'No symptom',\n",
    "    'SYMPTOMVERSION3': 0,\n",
    "    'SYMPTOM4': 'No symptom',\n",
    "    'SYMPTOMVERSION4': 0,\n",
    "}\n",
    "\n",
    "# Fill null values with predefined values for respective columns\n",
    "for column, value in fill_values.items():\n",
    "    vers_symptoms[column].fillna(value, inplace=True)\n",
    "\n",
    "# Calculate the percentage of null values in each column\n",
    "null_percentages = (vers_symptoms.isnull().sum() / len(vers_symptoms)) * 100\n",
    "print(null_percentages) \n",
    "\n",
    "# List to store columns with more than 50% null values\n",
    "columns_to_drop = []\n",
    "\n",
    "# Iterate through each column's null percentage\n",
    "for column, percentage in null_percentages.items():\n",
    "    if percentage > 50:\n",
    "        columns_to_drop.append(column)\n",
    "\n",
    "# Drop columns with more than 70% null values\n",
    "if columns_to_drop:\n",
    "    vers_symptoms.drop(columns=columns_to_drop, inplace=True)\n",
    "    print(f\"Dropped columns: {columns_to_drop}\")\n",
    "else:\n",
    "    print(\"No columns have more than 70% null values.\")\n",
    "### Showing updated data, with less null values.\n",
    "num_rows, num_columns = vers_data.shape\n",
    "print(f'Total number of rows in vers data: {num_rows}')\n",
    "print(f'Total number of columns in vers data: {num_columns}')\n",
    "print(f'Name of the columns: {vers_data.columns.tolist()}')\n",
    "num_rows, num_columns = vers_vax.shape\n",
    "print(f'Total number of rows in vers vax: {num_rows}')\n",
    "print(f'Total number of columns in vers vax: {num_columns}')\n",
    "print(f'Name of the columns: {vers_vax.columns.tolist()}')\n",
    "num_rows, num_columns = vers_symptoms.shape\n",
    "print(f'Total number of rows in vers symptoms: {num_rows}')\n",
    "print(f'Total number of columns in vers symptoms: {num_columns}')\n",
    "print(f'Name of the columns: {vers_symptoms.columns.tolist()}')\n",
    "### Data with 0 null values.\n",
    "# Removing rows with NaN values\n",
    "cleaned_vers_data = vers_data.dropna()\n",
    "\n",
    "num_rows, num_columns = cleaned_vers_data.shape\n",
    "\n",
    "print(f'Total number of rows: {num_rows}')\n",
    "print(f'Total number of columns: {num_columns}')\n",
    "# Removing rows with NaN values\n",
    "cleaned_vers_vax = vers_vax.dropna()\n",
    "\n",
    "num_rows, num_columns = cleaned_vers_vax.shape\n",
    "\n",
    "print(f'Total number of rows: {num_rows}')\n",
    "print(f'Total number of columns: {num_columns}')\n",
    "# Removing rows with NaN values\n",
    "cleaned_vers_symptoms = vers_symptoms.dropna()\n",
    "\n",
    "num_rows, num_columns = cleaned_vers_symptoms.shape\n",
    "\n",
    "print(f'Total number of rows: {num_rows}')\n",
    "print(f'Total number of columns: {num_columns}')\n",
    "### Merge all the cleaned data files into one and write it out in cleaned_vers_data.csv file.\n",
    "# Merge DataFrames based on the 'VERS_ID' column\n",
    "merged_df = pd.merge(cleaned_vers_data, cleaned_vers_vax, on='VAERS_ID', how='inner')\n",
    "merged_df = pd.merge(merged_df, cleaned_vers_symptoms, on='VAERS_ID', how='inner')\n",
    "\n",
    "num_rows, num_columns = merged_df.shape\n",
    "print(f'Total number of  rows in merged data: {num_rows}')\n",
    "print(f'Total number of columns in merged data: {num_columns}')\n",
    "\n",
    "# Writing it out in csv.\n",
    "# output_file_name = \"cleaned_vers_data.csv\"\n",
    "# merged_df.to_csv(output_file_name, index=False)\n",
    "df1 = pd.read_csv(\"cleaned_vers_data_2020.csv\", encoding='latin-1')\n",
    "df2 = pd.read_csv(\"cleaned_vers_data_2021.csv\", encoding='latin-1')\n",
    "df3 = pd.read_csv(\"cleaned_vers_data_2022.csv\", encoding='latin-1')\n",
    "\n",
    "filtered_data1 = df1[(df1['VAX_TYPE'] == 'COVID19') | (df1['VAX_TYPE'] == 'COVID19-2')]\n",
    "filtered_data2 = df2[(df2['VAX_TYPE'] == 'COVID19') | (df2['VAX_TYPE'] == 'COVID19-2')]\n",
    "filtered_data3 = df3[(df3['VAX_TYPE'] == 'COVID19') | (df3['VAX_TYPE'] == 'COVID19-2')]\n",
    "\n",
    "output_file_name1 = \"cleaned_vers_data_covid_2020.csv\"\n",
    "filtered_data1.to_csv(output_file_name1, index=False)\n",
    "\n",
    "\n",
    "output_file_name2 = \"cleaned_vers_data_covid_2021.csv\"\n",
    "filtered_data2.to_csv(output_file_name2, index=False)\n",
    "\n",
    "\n",
    "output_file_name3 = \"cleaned_vers_data_covid_2022.csv\"\n",
    "filtered_data3.to_csv(output_file_name3, index=False)\n",
    "\n",
    "df1 = pd.read_csv(\"cleaned_vers_data_covid_2020.csv\", encoding='latin-1')\n",
    "print(df1.shape)\n",
    "# Read the three CSV files\n",
    "file_paths = [\"cleaned_vers_data_covid_2020.csv\", \"cleaned_vers_data_covid_2021.csv\", \"cleaned_vers_data_covid_2022.csv\"]\n",
    "dfs = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Concatenate the dataframes\n",
    "df = pd.concat(dfs)\n",
    "print(df.shape)\n",
    "\n",
    "output_file_name = \"cleaned_vers_data_covid19_vaccine_2020-2022.csv\"\n",
    "df.to_csv(output_file_name, index=False)\n",
    "\n",
    "Total number of rows in vers data: 10381\n",
    "Total number of columns in vers data: 46\n",
    "Total number of rows: 7666\n",
    "Total number of columns: 46\n",
    "\n",
    "Total number of rows in vers data: 710783\n",
    "Total number of columns in vers data: 46\n",
    "Total number of rows: 445062\n",
    "Total number of columns: 46\n",
    "\n",
    "Total number of rows in vers data: 210736\n",
    "Total number of columns in vers data: 46\n",
    "Total number of rows: 104130\n",
    "Total number of columns: 46\n",
    "\n",
    "Total data 556,858"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
